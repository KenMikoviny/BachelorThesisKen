{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import torch_geometric.data as geom_data\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import Entities\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from torch_geometric.nn import RGCNConv, FastRGCNConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "dataset = Entities(cwd, \"MUTAG\")\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "available dataset info includes:  'name',\n",
    " 'num_classes',\n",
    " 'num_edge_features',\n",
    " 'num_features',\n",
    " 'num_node_features',\n",
    " 'num_relations',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data object: Data(edge_index=[2, 148454], edge_type=[148454], test_idx=[68], test_y=[68], train_idx=[272], train_y=[272])\n",
      "Length: 1\n",
      "Dataset:  MUTAGEntities()\n",
      "46 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Data object:\", dataset.data)\n",
    "print(\"Length:\", len(dataset))\n",
    "print(\"Dataset: \", dataset)\n",
    "#print(\"Average label: %4.2f\" % (dataset.data.y.float().mean().item()))\n",
    "print(dataset.num_relations, dataset.num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test\n",
    "torch.manual_seed(42)\n",
    "dataset.shuffle()\n",
    "train_dataset = dataset[:150]\n",
    "test_dataset = dataset[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch geometric automatically implements batching multiple graphs into 1 huge block diagonal adjacency matrix \n",
    "# + concatenates feature matrices etc.\n",
    "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=64) # Additional loader if you want to change to a larger dataset\n",
    "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BGS and AM graphs are too big to process them in a full-batch fashion.\n",
    "# Since our model does only make use of a rather small receptive field, we\n",
    "# filter the graph to only contain the nodes that are at most 2-hop neighbors\n",
    "# away from any training/test node.\n",
    "\n",
    "# k_hop_subgraph\n",
    "# Computes the k-hop subgraph of edge_index around node node_idx, returns:\n",
    "# (1) the nodes involved in the subgraph, \n",
    "# (2) the filtered edge_index connectivity, \n",
    "# (3) the mapping from node indices in node_idx to their new location, and \n",
    "# (4) the edge mask indicating which edges were preserved.\n",
    "\n",
    "node_idx = torch.cat([data.train_idx, data.test_idx], dim=0)\n",
    "node_idx, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "    node_idx, 2, data.edge_index, relabel_nodes=True)\n",
    "\n",
    "data.num_nodes = node_idx.size(0)\n",
    "data.edge_index = edge_index\n",
    "data.edge_type = data.edge_type[edge_mask]\n",
    "data.train_idx = mapping[:data.train_idx.size(0)]\n",
    "data.test_idx = mapping[data.train_idx.size(0):]\n",
    "\n",
    "np.unique(data.edge_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 38 graphs stacked together for the test dataset. The batch indices, stored in batch, show that the first 12 nodes belong to the first graph, the next 22 to the second graph, and so on.\n",
    "\n",
    "These indices are important for performing the final prediction. To perform a prediction over a whole graph, we usually perform a pooling operation over all nodes after running the GNN model. In this case, we will use the average pooling. Hence, we need to know which nodes should be included in which average pool. Using this pooling, we can already create our graph network below. Specifically, we re-use our class GNNModel from before, and simply add an average pool and single linear layer for the graph prediction task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = RGCNConv(data.num_nodes, 16, dataset.num_relations,\n",
    "                              num_bases=30)\n",
    "        self.conv2 = RGCNConv(16, dataset.num_classes, dataset.num_relations,\n",
    "                              num_bases=30)\n",
    "        self.node_embeddings = []\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "        x = self.conv2(x, edge_index, edge_type)   \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        # Here we save node embeddings for all nodes = shape [23606,2]\n",
    "        self.node_embeddings = x\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([30, 23606, 16])\n",
      "conv1.comp torch.Size([46, 30])\n",
      "conv1.root torch.Size([23606, 16])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([30, 16, 2])\n",
      "conv2.comp torch.Size([46, 30])\n",
      "conv2.root torch.Size([16, 2])\n",
      "conv2.bias torch.Size([2])\n",
      "conv1 weight torch.Size([30, 23606, 16])\n",
      "conv2 weight torch.Size([30, 16, 2])\n",
      "Edge index and edge type torch.Size([2, 148082]) torch.Size([148082])\n",
      "x shape before conv2 torch.Size([23606, 16])\n",
      "x shape after conv2 torch.Size([23606, 2])\n",
      "torch.Size([23606, 2])\n",
      "conv1.weight torch.Size([30, 23606, 16])\n",
      "conv1.comp torch.Size([46, 30])\n",
      "conv1.root torch.Size([23606, 16])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([30, 16, 2])\n",
      "conv2.comp torch.Size([46, 30])\n",
      "conv2.root torch.Size([16, 2])\n",
      "conv2.bias torch.Size([2])\n",
      "conv1 weight torch.Size([30, 23606, 16])\n",
      "conv2 weight torch.Size([30, 16, 2])\n",
      "Edge index and edge type torch.Size([2, 148082]) torch.Size([148082])\n",
      "x shape before conv2 torch.Size([23606, 16])\n",
      "x shape after conv2 torch.Size([23606, 2])\n",
      "torch.Size([23606, 2])\n",
      "Epoch: 01, Loss: 0.0218, Train: 1.0000 Test: 0.7206\n",
      "conv1.weight torch.Size([30, 23606, 16])\n",
      "conv1.comp torch.Size([46, 30])\n",
      "conv1.root torch.Size([23606, 16])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([30, 16, 2])\n",
      "conv2.comp torch.Size([46, 30])\n",
      "conv2.root torch.Size([16, 2])\n",
      "conv2.bias torch.Size([2])\n",
      "conv1 weight torch.Size([30, 23606, 16])\n",
      "conv2 weight torch.Size([30, 16, 2])\n",
      "Edge index and edge type torch.Size([2, 148082]) torch.Size([148082])\n",
      "x shape before conv2 torch.Size([23606, 16])\n",
      "x shape after conv2 torch.Size([23606, 2])\n",
      "torch.Size([23606, 2])\n",
      "conv1.weight torch.Size([30, 23606, 16])\n",
      "conv1.comp torch.Size([46, 30])\n",
      "conv1.root torch.Size([23606, 16])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([30, 16, 2])\n",
      "conv2.comp torch.Size([46, 30])\n",
      "conv2.root torch.Size([16, 2])\n",
      "conv2.bias torch.Size([2])\n",
      "conv1 weight torch.Size([30, 23606, 16])\n",
      "conv2 weight torch.Size([30, 16, 2])\n",
      "Edge index and edge type torch.Size([2, 148082]) torch.Size([148082])\n",
      "x shape before conv2 torch.Size([23606, 16])\n",
      "x shape after conv2 torch.Size([23606, 2])\n",
      "torch.Size([23606, 2])\n",
      "Epoch: 02, Loss: 0.0099, Train: 1.0000 Test: 0.7206\n",
      "conv1.weight torch.Size([30, 23606, 16])\n",
      "conv1.comp torch.Size([46, 30])\n",
      "conv1.root torch.Size([23606, 16])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([30, 16, 2])\n",
      "conv2.comp torch.Size([46, 30])\n",
      "conv2.root torch.Size([16, 2])\n",
      "conv2.bias torch.Size([2])\n",
      "conv1 weight torch.Size([30, 23606, 16])\n",
      "conv2 weight torch.Size([30, 16, 2])\n",
      "Edge index and edge type torch.Size([2, 148082]) torch.Size([148082])\n",
      "x shape before conv2 torch.Size([23606, 16])\n",
      "x shape after conv2 torch.Size([23606, 2])\n",
      "torch.Size([23606, 2])\n",
      "conv1.weight torch.Size([30, 23606, 16])\n",
      "conv1.comp torch.Size([46, 30])\n",
      "conv1.root torch.Size([23606, 16])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([30, 16, 2])\n",
      "conv2.comp torch.Size([46, 30])\n",
      "conv2.root torch.Size([16, 2])\n",
      "conv2.bias torch.Size([2])\n",
      "conv1 weight torch.Size([30, 23606, 16])\n",
      "conv2 weight torch.Size([30, 16, 2])\n",
      "Edge index and edge type torch.Size([2, 148082]) torch.Size([148082])\n",
      "x shape before conv2 torch.Size([23606, 16])\n",
      "x shape after conv2 torch.Size([23606, 2])\n",
      "torch.Size([23606, 2])\n",
      "Epoch: 03, Loss: 0.0056, Train: 1.0000 Test: 0.7206\n",
      "conv1.weight torch.Size([30, 23606, 16])\n",
      "conv1.comp torch.Size([46, 30])\n",
      "conv1.root torch.Size([23606, 16])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([30, 16, 2])\n",
      "conv2.comp torch.Size([46, 30])\n",
      "conv2.root torch.Size([16, 2])\n",
      "conv2.bias torch.Size([2])\n",
      "conv1 weight torch.Size([30, 23606, 16])\n",
      "conv2 weight torch.Size([30, 16, 2])\n",
      "Edge index and edge type torch.Size([2, 148082]) torch.Size([148082])\n",
      "x shape before conv2 torch.Size([23606, 16])\n",
      "x shape after conv2 torch.Size([23606, 2])\n",
      "torch.Size([23606, 2])\n",
      "conv1.weight torch.Size([30, 23606, 16])\n",
      "conv1.comp torch.Size([46, 30])\n",
      "conv1.root torch.Size([23606, 16])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([30, 16, 2])\n",
      "conv2.comp torch.Size([46, 30])\n",
      "conv2.root torch.Size([16, 2])\n",
      "conv2.bias torch.Size([2])\n",
      "conv1 weight torch.Size([30, 23606, 16])\n",
      "conv2 weight torch.Size([30, 16, 2])\n",
      "Edge index and edge type torch.Size([2, 148082]) torch.Size([148082])\n",
      "x shape before conv2 torch.Size([23606, 16])\n",
      "x shape after conv2 torch.Size([23606, 2])\n",
      "torch.Size([23606, 2])\n",
      "Epoch: 04, Loss: 0.0037, Train: 1.0000 Test: 0.6912\n",
      "conv1.weight torch.Size([30, 23606, 16])\n",
      "conv1.comp torch.Size([46, 30])\n",
      "conv1.root torch.Size([23606, 16])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([30, 16, 2])\n",
      "conv2.comp torch.Size([46, 30])\n",
      "conv2.root torch.Size([16, 2])\n",
      "conv2.bias torch.Size([2])\n",
      "conv1 weight torch.Size([30, 23606, 16])\n",
      "conv2 weight torch.Size([30, 16, 2])\n",
      "Edge index and edge type torch.Size([2, 148082]) torch.Size([148082])\n",
      "x shape before conv2 torch.Size([23606, 16])\n",
      "x shape after conv2 torch.Size([23606, 2])\n",
      "torch.Size([23606, 2])\n",
      "conv1.weight torch.Size([30, 23606, 16])\n",
      "conv1.comp torch.Size([46, 30])\n",
      "conv1.root torch.Size([23606, 16])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([30, 16, 2])\n",
      "conv2.comp torch.Size([46, 30])\n",
      "conv2.root torch.Size([16, 2])\n",
      "conv2.bias torch.Size([2])\n",
      "conv1 weight torch.Size([30, 23606, 16])\n",
      "conv2 weight torch.Size([30, 16, 2])\n",
      "Edge index and edge type torch.Size([2, 148082]) torch.Size([148082])\n",
      "x shape before conv2 torch.Size([23606, 16])\n",
      "x shape after conv2 torch.Size([23606, 2])\n",
      "torch.Size([23606, 2])\n",
      "Epoch: 05, Loss: 0.0027, Train: 1.0000 Test: 0.6765\n",
      "tensor([[ 0.7535,  0.5480],\n",
      "        [ 0.0173, -0.5691],\n",
      "        [ 0.4937,  0.3774],\n",
      "        ...,\n",
      "        [ 0.0519, -0.6032],\n",
      "        [ 0.7790, -0.5045],\n",
      "        [ 0.4050,  0.1781]])\n",
      "torch.Size([23606, 2])\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.edge_index, data.edge_type)\n",
    "    loss = F.nll_loss(out[data.train_idx], data.train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.edge_index, data.edge_type).argmax(dim=-1)\n",
    "    train_acc = pred[data.train_idx].eq(data.train_y).to(torch.float).mean()\n",
    "    test_acc = pred[data.test_idx].eq(data.test_y).to(torch.float).mean()\n",
    "    return train_acc.item(), test_acc.item()\n",
    "\n",
    "# originally 51\n",
    "for epoch in range(1, 6):\n",
    "    loss = train()\n",
    "    train_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {train_acc:.4f} '\n",
    "          f'Test: {test_acc:.4f}')\n",
    "    \n",
    "print(model.node_embeddings)\n",
    "print(model.node_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
